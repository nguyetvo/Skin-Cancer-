{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Skin Images to Features"},{"metadata":{},"cell_type":"markdown","source":"**Examining what we have**"},{"metadata":{},"cell_type":"markdown","source":"**What diseases do we have?**\n\nIn medicine the dx is an abbreviation for diagnosis and here these are short for.\n\nFrom the original text about the dataset we have this quite technical medical detail\nCases include a representative collection of all important diagnostic categories in the realm of pigmented lesions:\n\n- Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec)\n- basal cell carcinoma (bcc)\n- benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl)\n- dermatofibroma (df)\n- melanoma (mel)\n- melanocytic nevi (nv)\n- vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc). ### Simplified\n- nv  →  melanocytic nevi  →  0\n- mel  →  melanoma  →  1\n- bcc  →  basal cell carcinoma  →  2\n- akiec  →  Actinic keratoses and intraepithelial carcinoma  →  3\n- vasc  →  vascular lesions  →  4\n- bkl  →  benign keratosis-like lesions  →  5\n- df  →  dermatofibroma  →  6"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (15, 10)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'viridis' # grayscale looks better","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom skimage.io import imread as imread\nfrom skimage.util import montage as montage2d\nfrom skimage.color import label2rgb\nfrom PIL import Image\nbase_dir = Path('..') / 'input' / 'skin-cancer-mnist-ham10000'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load and Process Data\n\nimage_overview_df = pd.read_csv(base_dir / 'HAM10000_metadata.csv')\nall_image_ids = {c_path.stem: c_path for c_path in base_dir.glob('**/*.jpg')}\nimage_overview_df['image_path'] = image_overview_df['image_id'].map(all_image_ids.get)\nimage_overview_df.dropna(inplace=True) # remove values that are missing\nprint(image_overview_df.shape[0], 'image, recipe pairs loaded')\nimage_overview_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_overview_df.drop(['age'], axis=1).describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"dx_name_dict = {\n    'nv': 'melanocytic nevi',\n    'mel': 'melanoma',\n    'bcc': 'basal cell carcinoma',\n    'akiec': 'Actinic keratoses and intraepithelial carcinoma',\n    'vasc': 'vascular lesions',\n    'bkl': 'benign keratosis-like',\n    'df': 'dermatofibroma'\n}\nimage_overview_df['dx_name'] = image_overview_df['dx'].map(dx_name_dict.get)\ndx_name_id_dict = {name: id for id, name in enumerate(dx_name_dict.keys())}\nimage_overview_df['dx_id'] = image_overview_df['dx'].map(dx_name_id_dict.get).astype(int)\nimage_overview_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_overview_df['dx_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, 3, figsize=(20, 20))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), \n                            image_overview_df.head(9).iterrows()):\n    c_ax.imshow(imread(c_row['image_path']))\n    c_ax.set_title('{dx_name}\\nAge: {age}, Loc: {localization}'.format(**c_row))\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create Color Features**\n\n**We start with simple color features by grouping the image**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_row = image_overview_df.iloc[1]\nprint(test_row)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reduce the number of colors**\n\n**Currently we have 8-bit and 3 channels (Red, Green, Blue). This means we have 16,581,375 different colors. We can convert the image to 8-bit format to reduce the number of colors by a factor of 65536**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image = Image.open(test_row['image_path']) # normal image\n# convert to 8bit color (animated GIF) and then back\nweb_image = test_image.convert('P', palette='WEB', dither=None)\nfew_color_image = web_image.convert('RGB')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\nax1.imshow(test_image)\nax2.imshow(few_color_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Unique colors before', len(set([tuple(rgb) for rgb in np.array(test_image).reshape((-1, 3))])))\nprint('Unique colors after', len(set([tuple(rgb) for rgb in np.array(few_color_image).reshape((-1, 3))])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\nfor c_channel, c_name in enumerate(['red', 'green', 'blue']):\n    ax1.hist(np.array(test_image)[:, :, c_channel].ravel(), \n             color=c_name[0], \n             label=c_name, \n             bins=np.arange(256), \n             alpha=0.5)\n    ax2.hist(np.array(few_color_image)[:, :, c_channel].ravel(), \n             color=c_name[0], \n             label=c_name, \n             bins=np.arange(256), \n             alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How do the colors look?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_to_color = np.array(web_image.getpalette()).reshape((-1, 3))/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\nax1.imshow(few_color_image)\ncounts, bins = np.histogram(web_image, bins=np.arange(256))\nfor i in range(counts.shape[0]):\n    ax2.bar(bins[i], counts[i], color=idx_to_color[i])\nax2.set_yscale('log')\nax2.set_xlabel('Color Id')\nax2.set_ylabel('Pixel Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate for Many Images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def color_count_feature(in_path):\n    raw_image = Image.open(in_path) \n    web_image = raw_image.convert('P', palette='WEB', dither=None)\n    counts, bins = np.histogram(np.array(web_image).ravel(), bins=np.arange(256))\n    return counts*1.0/np.prod(web_image.size) # normalize output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimage_subset_df = image_overview_df.sample(100).copy()\nimage_subset_df['color_features'] = image_subset_df['image_path'].map(color_count_feature)\nimage_subset_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\ncombined_features = np.stack(image_subset_df['color_features'].values, 0)\nax1.imshow(combined_features)\nax1.set_title('Raw Color Counts')\nax1.set_xlabel('Color')\nax1.set_ylabel('Frequency')\ncolor_wise_average = np.tile(np.mean(combined_features, 0, keepdims=True), (combined_features.shape[0], 1))\nax2.imshow(combined_features/color_wise_average, vmin=0.05, vmax=20)\nax2.set_title('Normalized Color Counts')\nax2.set_xlabel('Color')\nax2.set_ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PCA Components**\n\n**We can use a tool called principle component analysis to show the images in features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nxy_pca = PCA(n_components=2)\nxy_coords = xy_pca.fit_transform(combined_features)\nimage_subset_df['x'] = xy_coords[:, 0]\nimage_subset_df['y'] = xy_coords[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(1,1, figsize=(15, 15))\nfor _, c_row in image_subset_df.iterrows():\n    ax1.plot(c_row['x'], c_row['y'], '*')\n    ax1.text(s=c_row['dx_name'][:15], x=c_row['x'], y=c_row['y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_xy_images(in_df, image_zoom=1):\n    fig, ax1 = plt.subplots(1,1, figsize=(10, 10))\n    artists = []\n    for _, c_row in in_df.iterrows():\n        c_img = Image.open(c_row['image_path']).resize((64, 64))\n        img = OffsetImage(c_img, zoom=image_zoom)\n        ab = AnnotationBbox(img, (c_row['x'], c_row['y']), xycoords='data', frameon=False)\n        artists.append(ax1.add_artist(ab))\n    ax1.update_datalim(in_df[['x', 'y']])\n    ax1.autoscale()\n    ax1.axis('off')\nshow_xy_images(image_subset_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TSNE Representation**\n\n**Rather than using simple PCA we can come up with a fancier representation called TSNE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne = TSNE(n_iter=250, verbose=True)\nxy_coords = tsne.fit_transform(combined_features)\nimage_subset_df['x'] = xy_coords[:, 0]\nimage_subset_df['y'] = xy_coords[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_xy_images(image_subset_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate for all images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimage_overview_df['color_features'] = image_overview_df['image_path'].map(color_count_feature).map(lambda x: x.tolist())\nimage_overview_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_overview_df['image_path'] = image_overview_df['image_path'].map(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_overview_df.to_json('color_features.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lh","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}